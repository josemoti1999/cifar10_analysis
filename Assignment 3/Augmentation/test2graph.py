
import matplotlib.pyplot as plt
list_x=[]
for i in range (90):
  list_x.append(i+1)
  
  
loss_train=[1.931011637458411, 1.2797534799636783, 1.0582551389094204, 0.9203021588837704, 0.8075197569244658, 0.7503943684155984, 0.686144952807585, 0.6408469840846098, 0.5963867143596835, 0.56730230156418, 0.5414929556114899, 0.5235286823776372, 0.4956502436524462, 0.4767623322699076, 0.4596900375907683, 0.44840182371609044, 0.4393308947000967, 0.42966784102380123, 0.4212964288032878, 0.41367812953946537, 0.4072532671720476, 0.3935905193047755, 0.38816604759458384, 0.384843065801179, 0.3910833338413702, 0.3753093314521453, 0.36850223398726917, 0.37466195351479914, 0.35745438117810224, 0.36707895346309827, 0.11428271060633233, 0.03488049674255159, 0.012410428703707807, 0.006024645455657979, 0.004118916622656004, 0.003618764395699324, 0.0034986471392862177, 0.0034960032764660277, 0.00341333020502306, 0.003095829852230256, 0.003217876357648074, 0.0051368982233392915, 0.0071318088697217156, 0.011122362539315086, 0.008603207354941179, 0.018275234885180316, 0.011988157708950512, 0.016588829977013875, 0.018899825087193487, 0.01922712964303506, 0.023787687122917085, 0.021124096515843325, 0.028237134827982128, 0.030378845155886982, 0.02699149339495565, 0.028438586408219984, 0.028972028676048873, 0.03322074068781665, 0.02872087078554856, 0.03722897826758263]
accuracy_train=[38.152, 54.044, 62.618, 67.72, 71.83, 73.792, 76.188, 77.77, 79.41, 80.304, 81.128, 81.896, 82.998, 83.512, 83.936, 84.45, 84.794, 85.056, 85.304, 85.724, 85.886, 86.476, 86.51, 86.618, 86.424, 86.96, 87.204, 87.158, 87.63, 87.316, 96.178, 99.072, 99.808, 99.928, 99.98, 99.99, 99.994, 99.996, 100.0, 100.0, 99.996, 99.94, 99.918, 99.726, 99.808, 99.458, 99.678, 99.49, 99.356, 99.41, 99.204, 99.308, 99.008, 98.974, 99.14, 99.078, 99.006, 98.922, 99.068, 98.76]
accuracy_test=[48.3, 58.97, 60.6, 65.9, 68.61, 69.54, 70.57, 71.8, 73.24, 72.21, 71.87, 73.31, 72.29, 72.64, 72.23, 72.62, 72.68, 73.5, 72.28, 71.88, 72.84, 72.76, 73.57, 73.29, 73.51, 73.92, 73.89, 73.73, 74.02, 74.07, 78.93, 78.73, 79.41, 79.21, 79.22, 79.25, 79.19, 79.22, 79.08, 79.0, 78.79, 78.74, 78.54, 78.65, 78.35, 78.51, 78.1, 78.19, 78.29, 77.52, 78.51, 76.37, 77.99, 76.58, 78.16, 77.69, 77.17, 75.27, 76.29, 76.8]
loss_test=[1.417399742603302, 1.171666857600212, 1.105844677090645, 0.9805744242668152, 0.9002564364671707, 0.8796962255239487, 0.86063625395298, 0.8252096670866013, 0.8209980392456054, 0.8350659316778183, 0.8406958693265915, 0.8372163182497024, 0.8393332880735397, 0.8457010573148728, 0.855361340045929, 0.8649331486225128, 0.8724945157766342, 0.8422189885377884, 0.8794922816753388, 0.8720406851172448, 0.8568820011615753, 0.8854509258270263, 0.8477170270681381, 0.8599411344528198, 0.8341443315148354, 0.8428175342082977, 0.8437242585420609, 0.8547719979286194, 0.8587580919265747, 0.8600496625900269, 0.8416382819414139, 0.9781159827113152, 1.027842911183834, 1.0655146437883376, 1.0912470176815987, 1.0948668876290322, 1.1079319483041763, 1.1272665697336197, 1.1483250644803047, 1.2341305148601531, 1.2487635922431946, 1.136177248954773, 1.2195980936288833, 1.2015908131003379, 1.2629358810186386, 1.2572484469413758, 1.2386518287658692, 1.224175084233284, 1.2722866427898407, 1.3369073963165283, 1.2016482228040695, 1.3708029967546462, 1.2457152473926545, 1.1981299167871475, 1.2135152506828308, 1.2159443122148514, 1.1644431537389754, 1.254360755085945, 1.2413994657993317, 1.2633031833171844]


loss_train=loss_train+[0.006128457636879686, 0.0009303518659238706, 0.0005852688818335142, 0.00045688743213289284, 0.00038907671784338974, 0.00034512253790793706, 0.00031572272216536754, 0.0002959323318071051, 0.0002823829041038285, 0.00027020581235127797, 0.0002632634490384492, 0.0002575416565703614, 0.0002541427474382305, 0.00025067500331822564, 0.00024813036137359343, 0.0002476043618165666, 0.00024802117894910983, 0.00024730409577410295, 0.000248026184733514, 0.000247312499114367, 0.00024985314330176625, 0.0002507071780121845, 0.00025168438928852054, 0.00025229763498355913, 0.0002553744961077686, 0.0002565137946548279, 0.00025993335583899884, 0.00026073567289382676, 0.00026229998033405625, 0.0002644444784775372]
accuracy_train=accuracy_train+[99.824, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]
accuracy_test=accuracy_test+[78.16, 78.34, 78.42, 78.37, 78.4, 78.33, 78.36, 78.38, 78.37, 78.38, 78.33, 78.37, 78.38, 78.44, 78.39, 78.37, 78.44, 78.47, 78.46, 78.45, 78.4, 78.43, 78.45, 78.38, 78.36, 78.32, 78.3, 78.3, 78.4, 78.43]
loss_test=loss_test+[1.2352788019180299, 1.2725602799654008, 1.2996268558502198, 1.3188872474431992, 1.3334315580129623, 1.3445713251829148, 1.3534996366500855, 1.3606358277797699, 1.3665857356786728, 1.3713546204566955, 1.375589381456375, 1.3792306810617447, 1.3821922826766968, 1.3850559949874879, 1.3876946872472764, 1.3902047610282897, 1.3923343908786774, 1.3945956474542618, 1.396745131611824, 1.3988918948173523, 1.4009591221809388, 1.4029734897613526, 1.4050509548187256, 1.4074616932868957, 1.409690033197403, 1.4122041749954224, 1.4146617859601975, 1.4170182251930237, 1.4196396225690842, 1.4224367201328278]





plt.figure(1)
plt.plot(list_x,loss_train,'-g')
plt.title('Test 2')
plt.xlabel('epochs')
plt.ylabel('Train set loss')
plt.legend(loc='best')
plt.savefig('test_2_train_loss')

plt.figure(2)
plt.ylim(0,105)
plt.plot(list_x,accuracy_train,'-g')
plt.title('Test 2')
plt.xlabel('epochs')
plt.ylabel('Train set Accuracy')
plt.legend(loc='best')
plt.savefig('test_2_train_accuracy')


plt.figure(3)
plt.ylim(0,105)
plt.plot(list_x,accuracy_test,'-g')
plt.title('Test 2')
plt.xlabel('epochs')
plt.ylabel('Test set Accuracy')
plt.legend(loc='best')
plt.savefig('test_2_test_accuracy')




plt.figure(4)
plt.plot(list_x,loss_test,'-g')
plt.title('Test 2')
plt.xlabel('epochs')
plt.ylabel('Test set Loss')
plt.legend(loc='best')
plt.savefig('test_2_test_loss')